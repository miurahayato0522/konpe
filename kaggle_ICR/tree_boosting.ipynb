{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "\n",
    "# Input data files are available in the read-only \"../input/\" directory\n",
    "# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n",
    "\n",
    "import os\n",
    "for dirname, _, filenames in os.walk('/kaggle/input'):\n",
    "    for filename in filenames:\n",
    "        print(os.path.join(dirname, filename))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import plotly.express as px\n",
    "%matplotlib inline\n",
    "import seaborn as sns\n",
    "import gc\n",
    "import re as re\n",
    "from collections import Counter\n",
    "\n",
    "from tqdm.auto import tqdm\n",
    "import math\n",
    "from sklearn.model_selection import KFold, StratifiedKFold, train_test_split, GridSearchCV\n",
    "from sklearn.metrics import roc_auc_score, accuracy_score, confusion_matrix, ConfusionMatrixDisplay, RocCurveDisplay\n",
    "from sklearn.preprocessing import LabelEncoder,StandardScaler\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "from glob import glob\n",
    "from pathlib import Path\n",
    "import joblib\n",
    "import pickle\n",
    "import os\n",
    "import random\n",
    "\n",
    "import time\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.metrics import log_loss\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train             = pd.read_csv('/kaggle/input/icr-identify-age-related-conditions/train.csv')\n",
    "test              = pd.read_csv('/kaggle/input/icr-identify-age-related-conditions/test.csv')\n",
    "greeks            = pd.read_csv('/kaggle/input/icr-identify-age-related-conditions/greeks.csv')\n",
    "submission_df = pd.read_csv('/kaggle/input/icr-identify-age-related-conditions/sample_submission.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def summary(df):\n",
    "    print(f'data shape: {df.shape}')\n",
    "    summ = pd.DataFrame(df.dtypes, columns=['data type'])\n",
    "    summ['#missing'] = df.isnull().sum().values \n",
    "    summ['%missing'] = df.isnull().sum().values / len(df)* 100\n",
    "    summ['#unique'] = df.nunique().values\n",
    "    desc = pd.DataFrame(df.describe(include='all').transpose())\n",
    "    summ['min'] = desc['min'].values\n",
    "    summ['max'] = desc['max'].values\n",
    "    summ['first quartile'] = desc.loc[:, '25%'].values\n",
    "    summ['second quartile'] = desc.loc[:, '50%'].values\n",
    "    summ['third quartile'] = desc.loc[:, '75%'].values\n",
    "    \n",
    "    return summ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "summary(train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# select numerical and categorical variables respectively.\n",
    "num_cols = test.select_dtypes(include=['float64']).columns.tolist()\n",
    "cat_cols = test.select_dtypes(include=['object']).columns.tolist()\n",
    "cat_cols.remove('Id')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig2 = px.pie(train, names='Class', \n",
    "             height=400, width=600, \n",
    "             hole=0.7, \n",
    "             title='target class Overview',\n",
    "                   color_discrete_sequence=['#4c78a8', '#72b7b2'])\n",
    "fig2.update_traces(hovertemplate=None, textposition='outside', textinfo='percent+label', rotation=0)\n",
    "fig2.update_layout(margin=dict(t=100, b=30, l=0, r=0), showlegend=False,\n",
    "                        plot_bgcolor='#fafafa', paper_bgcolor='#fafafa',\n",
    "                        title_font=dict(size=20, color='#555', family=\"Lato, sans-serif\"),\n",
    "                        font=dict(size=17, color='#8a8d93'),\n",
    "                        hoverlabel=dict(bgcolor=\"#444\", font_size=13, font_family=\"Lato, sans-serif\"))\n",
    "fig2.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "figsize = (4*4, 20)\n",
    "fig = plt.figure(figsize=figsize)\n",
    "for idx, col in enumerate(num_cols):\n",
    "    ax = plt.subplot(11,5, idx + 1)\n",
    "    sns.kdeplot(\n",
    "        data=train, hue='Class', fill=True,\n",
    "        x=col, palette=['#9E3F00', 'red'], legend=False\n",
    "    )\n",
    "            \n",
    "    ax.set_ylabel(''); ax.spines['top'].set_visible(False), \n",
    "    ax.set_xlabel(''); ax.spines['right'].set_visible(False)\n",
    "    ax.set_title(f'{col}', loc='right', \n",
    "                 weight='bold', fontsize=20)\n",
    "\n",
    "fig.suptitle(f'Features vs Target\\n\\n\\n', ha='center',  fontweight='bold', fontsize=21)\n",
    "fig.legend([1, 0], loc='upper center', bbox_to_anchor=(0.5, 0.96), fontsize=21, ncol=3)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_top_correlations(df: pd.core.frame.DataFrame, n: int, title_name: str='Top Correlations') -> None:\n",
    "    # Calculate correlation between all variables\n",
    "    corr = df.corr()\n",
    "\n",
    "    # Select variables having highest absolute correlation\n",
    "    top_corr_cols = corr.abs().nlargest(n, columns=corr.columns).index\n",
    "    top_corr = corr.loc[top_corr_cols, top_corr_cols]\n",
    "\n",
    "    fig, axes = plt.subplots(figsize=(10, 5))\n",
    "    mask = np.zeros_like(top_corr)\n",
    "    mask[np.triu_indices_from(mask)] = True\n",
    "    sns.heatmap(top_corr, mask=mask, linewidths=.5, cmap='YlOrRd', annot=True)\n",
    "    plt.title(title_name)\n",
    "    plt.show()\n",
    "\n",
    "# Plot heatmap of top 12 correlations in training data\n",
    "plot_top_correlations(train[num_cols], 12, 'Top 12 Correlations in Train Dataset')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import lightgbm as lgb\n",
    "import xgboost as xgb\n",
    "from catboost import Pool, CatBoostRegressor, CatBoostClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CFG:\n",
    "    VER = 1\n",
    "    AUTHOR = 'maverick'\n",
    "    COMPETITION = 'icr-identify-age-related-conditions'\n",
    "    DATA_PATH = Path('/kaggle/input/icr-identify-age-related-conditions')\n",
    "    OOF_DATA_PATH = Path('./oof')\n",
    "    MODEL_DATA_PATH = Path('./models')\n",
    "    METHOD_LIST = ['lightgbm', 'xgboost', 'catboost']\n",
    "    seed = 3407 #52\n",
    "    n_folds = 10 #replaced 20\n",
    "    target_col = 'Class'\n",
    "    metric = 'balanced_log_loss'\n",
    "    metric_maximize_flag = False\n",
    "    num_boost_round = 50500\n",
    "    early_stopping_round = 500\n",
    "    verbose = 2000\n",
    "    boosting_type = 'dart'\n",
    "    lgb_params = {\n",
    "        'objective': 'binary', # 'binary', 'multiclass'\n",
    "        'metric': None, # 'auc', 'multi_logloss'\n",
    "        # 'num_class': None,\n",
    "        'boosting': boosting_type,\n",
    "        'device_type':'cpu',\n",
    "        'learning_rate': 0.005,\n",
    "        'num_leaves': 5,\n",
    "        'feature_fraction': 0.50,\n",
    "        'bagging_fraction': 0.80,\n",
    "        'lambda_l1': 2, \n",
    "        'lambda_l2': 4,\n",
    "        'n_jobs': -1,\n",
    "        'is_unbalance':True, #added balancing\n",
    "        'verbose': -1, #added silence\n",
    "        # 'min_data_in_leaf': 40,\n",
    "        # 'bagging_freq': 10,\n",
    "        'seed': seed,\n",
    "    }\n",
    "    xgb_params = {\n",
    "        'objective': 'binary:logistic',\n",
    "        'eval_metric': 'logloss',\n",
    "        'learning_rate': 0.005, \n",
    "        'max_depth': 4,\n",
    "        'colsample_bytree': 0.50,\n",
    "        'subsample': 0.80,\n",
    "        'eta': 0.03,\n",
    "        'gamma': 1.5,\n",
    "        # 'lambda': 70,\n",
    "        # 'min_child_weight': 8,\n",
    "        # 'eval_metric':'logloss',\n",
    "        # 'tree_method': 'gpu_hist',\n",
    "        # 'predictor':'gpu_predictor',\n",
    "        'random_state': seed,\n",
    "    }\n",
    "    \n",
    "    cat_params = {\n",
    "        'learning_rate': 0.005, \n",
    "        'iterations': num_boost_round, \n",
    "        'depth': 4, # \n",
    "        'colsample_bylevel': 0.50,\n",
    "        'subsample': 0.80,\n",
    "        'l2_leaf_reg': 3, # 3, 30\n",
    "        'random_seed': seed,\n",
    "        'auto_class_weights': 'Balanced'\n",
    "        # 'task_type':'GPU', \n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!mkdir oof\n",
    "!mkdir models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test[CFG.target_col] = -1\n",
    "all_df = pd.concat([train, test])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# シードの設定\n",
    "def seed_everything(seed):\n",
    "    random.seed(seed)\n",
    "    np.random.seed(seed)\n",
    "    os.environ['PYTHONHASHSEED'] = str(seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def balanced_log_loss(y_true, y_pred):\n",
    "    y_pred = np.clip(y_pred, 1e-15, 1-1e-15)\n",
    "    nc = np.bincount(y_true)\n",
    "    w0, w1 = 1/(nc[0]/y_true.shape[0]), 1/(nc[1]/y_true.shape[0])\n",
    "    balanced_log_loss_score = (-w0/nc[0]*(np.sum(np.where(y_true==0,1,0) * np.log(1-y_pred))) - w1/nc[1]*(np.sum(np.where(y_true!=0,1,0) * np.log(y_pred)))) / (w0+w1)\n",
    "    return balanced_log_loss_score\n",
    "\n",
    "# ====================================================\n",
    "# LightGBM Metric\n",
    "# ====================================================\n",
    "def lgb_metric(y_pred, y_true):\n",
    "    y_true = y_true.get_label()\n",
    "    return 'balanced_log_loss', balanced_log_loss(y_true, y_pred), CFG.metric_maximize_flag\n",
    "\n",
    "def xgb_metric(y_pred, y_true):\n",
    "    y_true = y_true.get_label()\n",
    "    return 'balanced_log_loss', balanced_log_loss(y_true, y_pred)\n",
    "\n",
    "# ====================================================\n",
    "# Catboost Metric\n",
    "# ====================================================\n",
    "class CatboostMetric(object):\n",
    "    def get_final_error(self, error, weight): return error\n",
    "    def is_max_optimal(self): return CFG.metric_maximize_flag\n",
    "    def evaluate(self, approxes, target, weight):\n",
    "        error = balanced_log_loss(np.array(target), approxes)\n",
    "        return error, 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calc_log_loss_weight(y_true):\n",
    "    nc = np.bincount(y_true)\n",
    "    w0, w1 = 1/(nc[0]/y_true.shape[0]), 1/(nc[1]/y_true.shape[0])\n",
    "    return w0, w1\n",
    "\n",
    "def lightgbm_training(x_train: pd.DataFrame, y_train: pd.DataFrame, x_valid: pd.DataFrame, y_valid: pd.DataFrame, features: list, categorical_features: list):\n",
    "    train_w0, train_w1 = calc_log_loss_weight(y_train)\n",
    "    valid_w0, valid_w1 = calc_log_loss_weight(y_valid)\n",
    "    lgb_train = lgb.Dataset(x_train, y_train, weight=y_train.map({0: train_w0, 1: train_w1}), categorical_feature=categorical_features)\n",
    "    lgb_valid = lgb.Dataset(x_valid, y_valid, weight=y_valid.map({0: valid_w0, 1: valid_w1}), categorical_feature=categorical_features)\n",
    "    model = lgb.train(\n",
    "                params = CFG.lgb_params,\n",
    "                train_set = lgb_train,\n",
    "                num_boost_round = CFG.num_boost_round,\n",
    "                valid_sets = [lgb_train, lgb_valid],\n",
    "                early_stopping_rounds = CFG.early_stopping_round,\n",
    "                verbose_eval = CFG.verbose,\n",
    "                # feval = lgb_metric,\n",
    "            )\n",
    "    # Predict validation\n",
    "    valid_pred = model.predict(x_valid)\n",
    "    return model, valid_pred\n",
    "def xgboost_training(x_train: pd.DataFrame, y_train: pd.DataFrame, x_valid: pd.DataFrame, y_valid: pd.DataFrame, features: list, categorical_features: list):\n",
    "    train_w0, train_w1 = calc_log_loss_weight(y_train)\n",
    "    valid_w0, valid_w1 = calc_log_loss_weight(y_valid)\n",
    "    xgb_train = xgb.DMatrix(data=x_train, label=y_train, weight=y_train.map({0: train_w0, 1: train_w1}))\n",
    "    xgb_valid = xgb.DMatrix(data=x_valid, label=y_valid, weight=y_valid.map({0: valid_w0, 1: valid_w1}))\n",
    "    model = xgb.train(\n",
    "                CFG.xgb_params, \n",
    "                dtrain = xgb_train, \n",
    "                num_boost_round = CFG.num_boost_round, \n",
    "                evals = [(xgb_train, 'train'), (xgb_valid, 'eval')], \n",
    "                early_stopping_rounds = CFG.early_stopping_round, \n",
    "                verbose_eval = CFG.verbose,\n",
    "                # feval = xgb_metric, \n",
    "                # maximize = CFG.metric_maximize_flag, \n",
    "            )\n",
    "    # Predict validation\n",
    "    valid_pred = model.predict(xgb.DMatrix(x_valid), iteration_range=(0, model.best_ntree_limit))\n",
    "    return model, valid_pred\n",
    "    \n",
    "def catboost_training(x_train: pd.DataFrame, y_train: pd.DataFrame, x_valid: pd.DataFrame, y_valid: pd.DataFrame, features: list, categorical_features: list):\n",
    "    train_w0, train_w1 = calc_log_loss_weight(y_train)\n",
    "    valid_w0, valid_w1 = calc_log_loss_weight(y_valid)\n",
    "    cat_train = Pool(data=x_train, label=y_train, weight=y_train.map({0: train_w0, 1: train_w1}), cat_features=categorical_features)\n",
    "    cat_valid = Pool(data=x_valid, label=y_valid, weight=y_valid.map({0: valid_w0, 1: valid_w1}), cat_features=categorical_features)\n",
    "    model = CatBoostClassifier(**CFG.cat_params) # , eval_metric = CatboostMetric\n",
    "    model.fit(cat_train, \n",
    "              eval_set=[cat_valid],\n",
    "              early_stopping_rounds=CFG.early_stopping_round, \n",
    "              verbose=CFG.verbose, \n",
    "              use_best_model=True)\n",
    "    # Predict validation\n",
    "    valid_pred = model.predict_proba(x_valid)[:, 1]\n",
    "    return model, valid_pred\n",
    "\n",
    "def gradient_boosting_model_cv_training(method: str, train_df: pd.DataFrame, features: list, categorical_features: list):\n",
    "    # Create a numpy array to store out of folds predictions\n",
    "    oof_predictions = np.zeros(len(train_df))\n",
    "    oof_fold = np.zeros(len(train_df))\n",
    "    kfold = StratifiedKFold(n_splits = CFG.n_folds, shuffle = True, random_state = CFG.seed)\n",
    "    for fold, (train_index, valid_index) in enumerate(kfold.split(train_df, train_df[CFG.target_col])):\n",
    "        print('-'*50)\n",
    "        print(f'{method} training fold {fold + 1}')\n",
    "        \n",
    "        x_train = train_df[features].iloc[train_index]\n",
    "        y_train = train_df[CFG.target_col].iloc[train_index]\n",
    "        x_valid = train_df[features].iloc[valid_index]\n",
    "        y_valid = train_df[CFG.target_col].iloc[valid_index]\n",
    "        if method == 'lightgbm':\n",
    "            model, valid_pred = lightgbm_training(x_train, y_train, x_valid, y_valid, features, categorical_features)\n",
    "        if method == 'xgboost':\n",
    "            model, valid_pred = xgboost_training(x_train, y_train, x_valid, y_valid, features, categorical_features)\n",
    "        if method == 'catboost':\n",
    "            model, valid_pred = catboost_training(x_train, y_train, x_valid, y_valid, features, categorical_features)\n",
    "        \n",
    "        # Save best model\n",
    "        pickle.dump(model, open(CFG.MODEL_DATA_PATH / f'{method}_fold{fold + 1}_seed{CFG.seed}_ver{CFG.VER}.pkl', 'wb'))\n",
    "        # Add to out of folds array\n",
    "        oof_predictions[valid_index] = valid_pred\n",
    "        oof_fold[valid_index] = fold + 1\n",
    "        del x_train, x_valid, y_train, y_valid, model, valid_pred\n",
    "        gc.collect()\n",
    "\n",
    "    # Compute out of folds metric\n",
    "    score = balanced_log_loss(train_df[CFG.target_col], oof_predictions)\n",
    "    print(f'{method} our out of folds CV score is {score}')\n",
    "    # Create a dataframe to store out of folds predictions\n",
    "    oof_df = pd.DataFrame({'Id': train_df['Id'], CFG.target_col: train_df[CFG.target_col], f'{method}_prediction': oof_predictions, 'fold': oof_fold})\n",
    "    oof_df.to_csv(CFG.MODEL_DATA_PATH / f'oof_{method}_seed{CFG.seed}_ver{CFG.VER}.csv', index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "numerical_features = ['AB', 'AF', 'AH', 'AM', 'AR', 'AX', 'AY', 'AZ', #'BC', \n",
    "                      'BD', 'BN', 'BP', 'BQ', 'BR', 'BZ',\n",
    "                      'CB', 'CC', 'CD', 'CF', 'CH', #'CL', \n",
    "                      'CR', 'CS', 'CU', 'CW',\n",
    "                      'DA', 'DE', 'DF', 'DH', 'DI', 'DL', 'DN', 'DU', 'DV', 'DY',\n",
    "                      'EB', 'EE', 'EG', 'EH', 'EL', 'EP', 'EU',\n",
    "                      'FC', 'FD', 'FE', 'FI', 'FL', 'FR', 'FS',\n",
    "                      'GB', 'GE', 'GF', 'GH', 'GI', 'GL']\n",
    "categorical_features = ['EJ']\n",
    "features = numerical_features + categorical_features\n",
    "str2int_dict = {}\n",
    "str2int_dict['EJ'] = {'A': 1, 'B': 0}\n",
    "seed_everything(CFG.seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Preprocessing(input_df: pd.DataFrame)->pd.DataFrame:\n",
    "    input_df = input_df.rename(columns={'BD ': 'BD', 'CD ': 'CD', 'CW ': 'CW', 'FD ': 'FD'}) #?\n",
    "    output_df = input_df.copy()\n",
    "    sc = StandardScaler()\n",
    "    output_df[numerical_features] = sc.fit_transform(output_df[numerical_features]) #added scaling\n",
    "    for col in categorical_features:\n",
    "        output_df[col] = input_df[col].map(str2int_dict[col])\n",
    "    return output_df\n",
    "all_df = Preprocessing(all_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df = all_df[all_df[CFG.target_col] != -1].copy()\n",
    "test_df = all_df[all_df[CFG.target_col] == -1].copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for method in CFG.METHOD_LIST:\n",
    "    gradient_boosting_model_cv_training(method, train_df, features, categorical_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def lightgbm_inference(x_test: pd.DataFrame):\n",
    "    test_pred = np.zeros(len(x_test))\n",
    "    for fold in range(CFG.n_folds):\n",
    "        model = pickle.load(open(CFG.MODEL_DATA_PATH / f'lightgbm_fold{fold + 1}_seed{CFG.seed}_ver{CFG.VER}.pkl', 'rb'))\n",
    "        # Predict\n",
    "        test_pred += model.predict(x_test)\n",
    "    return test_pred / CFG.n_folds\n",
    "def xgboost_inference(x_test: pd.DataFrame):\n",
    "    test_pred = np.zeros(len(x_test))\n",
    "    for fold in range(CFG.n_folds):\n",
    "        model = pickle.load(open(CFG.MODEL_DATA_PATH / f'xgboost_fold{fold + 1}_seed{CFG.seed}_ver{CFG.VER}.pkl', 'rb'))\n",
    "        # Predict\n",
    "        test_pred += model.predict(xgb.DMatrix(x_test), iteration_range=(0, model.best_ntree_limit))\n",
    "    return test_pred / CFG.n_folds\n",
    "    \n",
    "def catboost_inference(x_test: pd.DataFrame):\n",
    "    test_pred = np.zeros(len(x_test))\n",
    "    for fold in range(CFG.n_folds):\n",
    "        model = pickle.load(open(CFG.MODEL_DATA_PATH / f'catboost_fold{fold + 1}_seed{CFG.seed}_ver{CFG.VER}.pkl', 'rb'))\n",
    "        # Predict\n",
    "        test_pred += model.predict_proba(x_test)[:, 1]\n",
    "    return test_pred / CFG.n_folds\n",
    "\n",
    "def gradient_boosting_model_inference(method: str, test_df: pd.DataFrame, features: list, categorical_features: list):\n",
    "    x_test = test_df[features]\n",
    "    if method == 'lightgbm':\n",
    "        test_pred = lightgbm_inference(x_test)\n",
    "    if method == 'xgboost':\n",
    "        test_pred = xgboost_inference(x_test)\n",
    "    if method == 'catboost':\n",
    "        test_pred = catboost_inference(x_test)\n",
    "    return test_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for method in CFG.METHOD_LIST:\n",
    "    test_df[f'{method}_pred_prob'] = gradient_boosting_model_inference(method, test_df, features, categorical_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_df['class_1'] = 0.9 * test_df['lightgbm_pred_prob'] + 0.05 * test_df['xgboost_pred_prob'] + 0.05 * test_df['catboost_pred_prob']\n",
    "test_df['class_0'] = 1 - test_df['class_1']\n",
    "test_df[list(submission_df)].to_csv('submission.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_df[list(submission_df)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
