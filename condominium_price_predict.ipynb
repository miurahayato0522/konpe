{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "083c4800-df6b-4376-a636-9206dcbbc392",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "## import文"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6e836ebd-6929-4ee7-8104-2ac0b432e50d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from PIL import Image\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import seaborn as sns\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "import tensorflow as tf\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.linear_model import Ridge\n",
    "from sklearn.linear_model import Lasso\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.linear_model import ElasticNet\n",
    "from sklearn.svm import SVR\n",
    "from sklearn.ensemble import GradientBoostingRegressor\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "import xgboost as xgb\n",
    "from catboost import CatBoostRegressor\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.svm import LinearSVR\n",
    "from sklearn.linear_model import Ridge\n",
    "from sklearn.svm import SVR\n",
    "from sklearn.linear_model import ElasticNet\n",
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import warnings\n",
    "import re\n",
    "import lightgbm as lgb\n",
    "import catboost\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout\n",
    "from keras.callbacks import EarlyStopping\n",
    "from sklearn.datasets import load_boston\n",
    "import optuna\n",
    "from functools import partial\n",
    "from sklearn.model_selection import train_test_split\n",
    "#交差検証に必要なライブラリ\n",
    "from sklearn.model_selection import cross_validate\n",
    "# スコア計算のためのライブラリ\n",
    "from sklearn.metrics import r2_score\n",
    "from sklearn.metrics import mean_absolute_error,mean_squared_error\n",
    "from sklearn.metrics import roc_curve, recall_score, confusion_matrix, accuracy_score\n",
    "#時刻を計測するライブラリ\n",
    "import time\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from keras import metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f27d34ea-59a7-4502-8b8c-f17d7e9f0a22",
   "metadata": {},
   "outputs": [],
   "source": [
    "warnings.simplefilter('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "611f601d-6ef1-4337-8612-8094f514d66d",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "## データ準備"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "23144763-f4ec-4561-928e-c67fd33f6edf",
   "metadata": {},
   "source": [
    "データファイルの作成と前処理"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9427946c-8aaf-4c21-a64a-6763c5a55138",
   "metadata": {},
   "outputs": [],
   "source": [
    "#データの読み込みと連結 \n",
    "path = \"./train\"\n",
    "files = glob.glob(path+\"/*.csv\")\n",
    "\n",
    "data_list = []\n",
    "for file in files:\n",
    "  # 全ファイルをdata_frameに変換し、その値を配列に格納する\n",
    "  # index_col=0のようにindexとして使いたい列の列番号を0始まりで指定する。\n",
    "    data_list.append(pd.read_csv(file, index_col=0))\n",
    "\n",
    "# 配列に格納したデータフレームを１つにまとめる\n",
    "df = pd.concat(data_list)\n",
    "\n",
    "# データの行数とカラム数の確認\n",
    "df.shape\n",
    "\n",
    "# 欠損値やデータ型の確認\n",
    "# 0 non-nullのデータは欠損値のため、削除する\n",
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bfff1056-ac89-48bd-8dde-3626a3d21a64",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 欠損数確認\n",
    "df.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3092712-3e32-484d-971e-9abb3b30ce84",
   "metadata": {},
   "outputs": [],
   "source": [
    "#欠損値のみの列を削除\n",
    "nonnull_list = []\n",
    "for col in df.columns:\n",
    "  count = df[col].count()\n",
    "  if count == 0:\n",
    "    nonnull_list.append(col)\n",
    "df = df.drop(nonnull_list, axis = 1)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2243b9da-76b8-4f59-8717-b688295b635f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#欠損値のないデータが40万件未満の列を削除\n",
    "nonnull_list = []\n",
    "for col in df.columns:\n",
    "  count = df[col].count()\n",
    "  if count < 400000:\n",
    "    nonnull_list.append(col)\n",
    "df = df.drop(nonnull_list, axis = 1) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "152d953b-c2d7-4d2c-8e98-17d2d2c1cee0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 曖昧な表現を修正\n",
    "dis = {\n",
    "    \"30分?60分\": 45,\n",
    "    \"1H?1H30\": 75,\n",
    "    \"2H?\": 120,\n",
    "    \"1H30?2H\": 105\n",
    "}\n",
    "df[\"最寄駅：距離（分）\"] = df[\"最寄駅：距離（分）\"].replace(dis).astype(float)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1bcf79b3-d54e-4091-96b0-75cda3444ac7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 市区町村コードと地区名を合わせたtown_list列を新規に作成\n",
    "df['town_list'] = df['市区町村コード'].astype(str).str.cat(df['地区名'],sep='_')\n",
    "\n",
    "# 各欠損値を同地区の平均で補完（また不要な列などは削除しておく）,ここでは最寄り駅の例のみ示す\n",
    "flg_is_null = df[\"最寄駅：距離（分）\"].isnull()\n",
    "for trg in list(df.loc[flg_is_null,\"town_list\"].unique()):\n",
    "    station_kyori = df.loc[(~flg_is_null) & (df[\"town_list\"] == trg),\"最寄駅：距離（分）\"].mean()\n",
    "    df[\"最寄駅：距離（分）\"].loc[(flg_is_null) & (df[\"town_list\"] == trg)] = station_kyori"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ba4c64c-75f6-40cd-be07-ca036767fcb3",
   "metadata": {},
   "source": [
    "その他、要素が文字のものは数値に変換している（平成7年→1995など）"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1ba90c6-6f3e-4222-8c25-f2aa15457432",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train = pd.read_csv(\"./train_merge.csv\")\n",
    "df_test = pd.read_csv(\"./test.csv\")\n",
    "\n",
    "X_train = train_te['value'] \n",
    "Y_train = train_te.drop([\"value\"],axis=1)\n",
    "test = df_test"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "308c85ec-0216-4ade-ba8f-6d89eb9dd798",
   "metadata": {
    "tags": []
   },
   "source": [
    "## モデル構築と学習"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "47f8b380-a951-4379-9f0c-d911878d7a34",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "##### XGBoost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "155826e7-7674-4e6a-993a-2d38e4c3d53e",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Model_XGB:\n",
    "    def __init__(self):\n",
    "        self.model = None\n",
    "\n",
    "    def fit(self, tr_x, tr_y, va_x, va_y):\n",
    "        xgb_params = {'objective': 'reg:squarederror',\n",
    "                      'max_depth':108,\n",
    "                      'max_leaves':273,\n",
    "                      'learning_rate':0.2,\n",
    "                      'n_estimators':25000,\n",
    "                      'eta':0.0006,\n",
    "                      'gamma':0.18,\n",
    "                      'min_child_weight':0.005,\n",
    "                      'max_delta_step':0.28,\n",
    "                      'subsample':0.77,\n",
    "                      'reg_lambda':94.8,\n",
    "                      'reg_alpha':6.3,\n",
    "                      'random_state': 10,\n",
    "                     }\n",
    "        dtrain = xgb.DMatrix(tr_x, label = tr_y)\n",
    "        dvalid = xgb.DMatrix(va_x, label = va_y)\n",
    "        evals = [(dtrain, 'train'), (dvalid, 'eval')]\n",
    "        self.model = xgb.train(xgb_params, dtrain, num_boost_round = 10000,early_stopping_rounds = 40,verbose_eval = 200, evals = evals)\n",
    "\n",
    "    def predict(self, x):\n",
    "        data = xgb.DMatrix(x)\n",
    "        pred = self.model.predict(data)\n",
    "        return pred"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "49424c8c-3734-4e29-9e04-15ec61079d98",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "#### lightGBM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7247a4b1-0579-4a70-acad-60cdc7749c2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Model_lgb:\n",
    "    def __init__(self):\n",
    "        self.model = None\n",
    "\n",
    "    def fit(self, tr_x, tr_y, va_x, va_y):\n",
    "        lgb_params = {'objective': 'regression_l1',\n",
    "                      'boosting_type' : 'gbdt',\n",
    "                      'metrics':'rmse',\n",
    "                      'num_leaves':1813,\n",
    "                      'learning_rate':0.02,\n",
    "                      'n_estimators':25000,\n",
    "                      'seed':10,\n",
    "                      'lambda_l1':3.6,\n",
    "                      'lambda_l2':0.3,\n",
    "                      'tree_learner':'feature',\n",
    "                      'feature_fraction':0.98,\n",
    "                      'bagging_fraction':0.94,\n",
    "                      'bagging_freq':1,\n",
    "                      'min_child_samples':58,\n",
    "                      'max_depth':102,\n",
    "                      'min_data_in_leaf':45,\n",
    "                      'feature_pre_filter':'false',\n",
    "                     }\n",
    "        \n",
    "        lgb_train = lgb.Dataset(tr_x, label = tr_y)\n",
    "        lgb_eval = lgb.Dataset(va_x, label = va_y,reference = lgb_train)\n",
    "        self.model = lgb.train(lgb_params, lgb_train, valid_sets = lgb_eval, num_boost_round = 10000,early_stopping_rounds = 100,verbose_eval = 100)\n",
    "\n",
    "    def predict(self, x):\n",
    "        pred = self.model.predict(x,num_iteration = self.model.best_iteration)\n",
    "        return pred"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "348f4267-6870-4f5e-804e-3098d56ed27a",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "#### catboost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aecf1a6c-4dff-4bdf-a19f-db5ab90cf815",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Model_catboost:\n",
    "\n",
    "    def __init__(self):\n",
    "        self.model = None\n",
    "\n",
    "    def fit(self, tr_x, tr_y, va_x, va_y):\n",
    "        #https://catboost.ai/docs/concepts/python-reference_catboostregressor.html\n",
    " \n",
    "        cat_features_index = [0, 1, 2, 3, 4,6,7,8,9,12]\n",
    "        catb = catboost.CatBoostRegressor(\n",
    "                                    iterations = 10000, \n",
    "                                    learning_rate = 0.3,\n",
    "                                    use_best_model = True, \n",
    "                                    random_seed = 3, \n",
    "                                    random_strength = 69,\n",
    "                                    bagging_temperature = 0.092,\n",
    "                                    od_type ='IncToDec',\n",
    "                                    od_wait = 45,\n",
    "                                    l2_leaf_reg = 3,\n",
    "                                    depth = 11,\n",
    "                                    loss_function = \"RMSE\",\n",
    "                                  )\n",
    " \n",
    "        self.model = catb.fit(tr_x,tr_y,eval_set = (va_x,va_y),cat_features = cat_features_index,early_stopping_rounds = 40,verbose_eval = 50)\n",
    "        print(self.model.score(va_x,va_y))\n",
    "    def predict(self, x):\n",
    "        pred = self.model.predict(x)\n",
    "        return pred"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d775e77f-8a19-4d4d-9aec-897ed3745f57",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "#### linearsvm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84bc7e4c-2dc5-4388-8125-adf938e6da3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Model_LinearSVR:\n",
    "    def __init__(self):\n",
    "        self.model = None\n",
    "\n",
    "    def fit(self, tr_x, tr_y, va_x, va_y):\n",
    "        self.scaler = StandardScaler()\n",
    "        self.scaler.fit(tr_x)\n",
    "        tr_x = self.scaler.transform(tr_x)\n",
    "        #params = {\"C\":np.logspace(0,1,params_cnt),\"epsilon\":np.logspace(-1,1,params_cnt)}\n",
    "        self.model = LinearSVR(max_iter = 1000,\n",
    "                               random_state = 10,\n",
    "                               C = 0.1, #損失の係数（正則化係数の逆数）\n",
    "                               epsilon = 0.01\n",
    "\n",
    "                              )\n",
    "        self.model.fit(tr_x,tr_y)\n",
    "\n",
    "    def predict(self,x):\n",
    "        x = self.scaler.transform(x)\n",
    "        pred = self.model.predict(x)\n",
    "        return pred"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "641472c4-a766-4e87-9a4b-92e7a05f9e65",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "#### カーネルsvm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "632892be-3503-480a-9bbd-9c507a49a176",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Model_KernelSVR:\n",
    "\n",
    "    def __init__(self):\n",
    "        self.model = None\n",
    "\n",
    "    def fit(self, tr_x, tr_y, va_x, va_y):\n",
    "        self.scaler = StandardScaler()\n",
    "        self.scaler.fit(tr_x)\n",
    "        tr_x = self.scaler.transform(tr_x)\n",
    "        #params = {\"kernel\":['rbf'],\"C\":np.logspace(0,1,params_cnt), \"epsilon\":np.logspace(-1,1,params_cnt)}\n",
    "        self.model = SVR(kernel = 'rbf',\n",
    "                         gamma = 0.4,\n",
    "                         max_iter = 1000,\n",
    "                         C = 100, #損失の係数（正則化係数の逆数）\n",
    "                         epsilon = 0.4,\n",
    "                         degree = 1\n",
    "\n",
    "                              )\n",
    "        self.model.fit(tr_x,tr_y)\n",
    "\n",
    "    def predict(self,x):\n",
    "        x = self.scaler.transform(x)\n",
    "        pred = self.model.predict(x)\n",
    "        return pred\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "551a127a-dd14-4701-8819-53fbccaadc92",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "#### ElasticNet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d23a3887-d049-4106-bfe8-de5ba0fdf3c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Model_ElasticNet:\n",
    "\n",
    "    def __init__(self):\n",
    "        self.model = None\n",
    "\n",
    "    def fit(self, tr_x, tr_y, va_x, va_y):\n",
    "        '''1 / (2 * n_samples) * ||y - Xw||^2_2\n",
    "        + alpha * l1_ratio * ||w||_1\n",
    "        + 0.5 * alpha * (1 - l1_ratio) * ||w||^2_2\n",
    "       ref)  https://scikit-learn.org/stable/modules/generated/sklearn.linear_model.ElasticNet.html\n",
    "        '''\n",
    "\n",
    "        self.scaler = StandardScaler()\n",
    "        self.scaler.fit(tr_x)\n",
    "        tr_x = self.scaler.transform(tr_x)\n",
    "        self.model = ElasticNet(\n",
    "            alpha = 0.05, #L1係数\n",
    "            l1_ratio = 0.5,\n",
    "                              )\n",
    "        self.model.fit(tr_x,tr_y)\n",
    "\n",
    "    def predict(self,x):\n",
    "        x = self.scaler.transform(x)\n",
    "        pred = self.model.predict(x)\n",
    "        return pred"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e9a684f-5947-42aa-a100-0cdffada06b0",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "#### KNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5d94f11-5eed-4a22-835b-53849d49e417",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Model_KNN:\n",
    "    def __init__(self):\n",
    "        self.model = None\n",
    "\n",
    "    def fit(self, tr_x, tr_y, va_x, va_y):\n",
    "        self.scaler = StandardScaler()\n",
    "        self.scaler.fit(tr_x)\n",
    "        tr_x = self.scaler.transform(tr_x)\n",
    "        #params = {\"kernel\":['rbf'],\"C\":np.logspace(0,1,params_cnt), \"epsilon\":np.logspace(-1,1,params_cnt)}\n",
    "        self.model = KNeighborsRegressor(n_neighbors = 13,\n",
    "                                         weights = 'distance',\n",
    "                                         algorithm = 'kd_tree',\n",
    "                                         leaf_size = 218\n",
    "                                        )\n",
    "\n",
    "        self.model.fit(tr_x,tr_y)\n",
    "\n",
    "    def predict(self,x):\n",
    "        x = self.scaler.transform(x)\n",
    "        pred = self.model.predict(x)\n",
    "        return pred"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2162a016-6aee-4006-b7a0-fb1afaef02fa",
   "metadata": {
    "tags": []
   },
   "source": [
    "#### out of fold(実行関数定義)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68f89acf-d87d-4f24-9120-147318b5044b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_cv(model, train_x, train_y, test_x):\n",
    "    preds = []\n",
    "    preds_test = []\n",
    "    va_idxes = []\n",
    "\n",
    "    kf = KFold(n_splits=3, shuffle=True, random_state=10)\n",
    "\n",
    "    # クロスバリデーションで学習・予測を行い、予測値とインデックスを保存する\n",
    "    for i, (tr_idx, va_idx) in enumerate(kf.split(train_x)):\n",
    "        tr_x, va_x = train_x.iloc[tr_idx], train_x.iloc[va_idx]\n",
    "        tr_y, va_y = train_y.iloc[tr_idx], train_y.iloc[va_idx]\n",
    "        model.fit(tr_x, tr_y, va_x, va_y)\n",
    "        pred = model.predict(va_x)\n",
    "        preds.append(pred)\n",
    "        pred_test = model.predict(test_x)\n",
    "        preds_test.append(pred_test)\n",
    "        va_idxes.append(va_idx)\n",
    "\n",
    "    # バリデーションデータに対する予測値を連結し、その後元の順序に並べ直す\n",
    "    va_idxes = np.concatenate(va_idxes)\n",
    "    preds = np.concatenate(preds, axis=0)\n",
    "    order = np.argsort(va_idxes)\n",
    "    pred_train = preds[order]\n",
    "\n",
    "    # テストデータに対する予測値の平均をとる\n",
    "    preds_test = np.mean(preds_test, axis=0)\n",
    "\n",
    "    return pred_train, preds_test"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e4fdd6bf",
   "metadata": {},
   "source": [
    "### 実行"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74dd53bd-67fd-4c91-90d7-9035609af702",
   "metadata": {},
   "outputs": [],
   "source": [
    "#XGBoost\n",
    "model_1 = Model_XGB()\n",
    "pred_train_1, pred_test_1 = predict_cv(model_1, X_train, Y_train, test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "38bbc61b-f74d-4904-ae7d-362e24182d4e",
   "metadata": {},
   "source": [
    "他モデルも同様に実行、また特徴量の重要度など確認"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "441cec7d-59f2-4bde-8dba-68119618d480",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 結果保存\n",
    "\n",
    "'''\n",
    "以下では、１層目の予測値をデータフレームにまとめている。\n",
    "データフレームにまとめて、２層目の特徴量として、まとめている\n",
    "'''\n",
    "train_x_1 = pd.DataFrame({\n",
    "                          'pred_1b_lgbm': pred_train_1,\n",
    "                         })\n",
    "test_x_1 = pd.DataFrame({\n",
    "                          'pred_1b_lgbm': pred_test_1,\n",
    "                         })\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5779ebd6-556f-4624-9954-e0b2d12917de",
   "metadata": {},
   "source": [
    "これらの出力結果を新たなる特徴量として繰り返すことでスタッキング手法になる"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2bad7b91-c4cc-44a0-a2be-41efa998dfe7",
   "metadata": {},
   "source": [
    "## その他（optuna）"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f2e3eaa-e908-40dd-a7ae-84bdec1f7504",
   "metadata": {},
   "outputs": [],
   "source": [
    "# lightgbm\n",
    "def objective(trial):\n",
    "    train_x, test_x, train_y, test_y = train_test_split(X_train, y_train, test_size=0.2, random_state=334)\n",
    "    # LightGBMを利用するのに必要なフォーマットに変換\n",
    "    lgb_train = lgb.Dataset(train_x, train_y)\n",
    "    lgb_eval = lgb.Dataset(test_x, test_y)\n",
    "    \n",
    "    param = {\n",
    "        'task': 'train',                 # タスクを訓練に設定\n",
    "        'boosting_type': 'gbdt',         # GBDTを指定\n",
    "        'objective': trial.suggest_categorical('objective',['regression','regression_l1']),    \n",
    "        'metric': 'rmse',\n",
    "        'lambda_l1': trial.suggest_loguniform('lambda_l1', 1e-6, 10.0),\n",
    "        'lambda_l2': trial.suggest_loguniform('lambda_l2', 1e-6, 10.0),\n",
    "        'num_leaves': trial.suggest_int('num_leaves', 2, 4096),\n",
    "        'learning_rate' : trial.suggest_uniform('learning_rate', 0.01, 1.0),\n",
    "        'tree_learner' : trial.suggest_categorical('tree_learner', [\"serial\", \"feature\", \"data\", \"voting\"]),\n",
    "        'feature_fraction': trial.suggest_uniform('feature_fraction', 0.3, 1.0),\n",
    "        'bagging_fraction': trial.suggest_uniform('bagging_fraction', 0.3, 1.0),\n",
    "        'bagging_freq': trial.suggest_int('bagging_freq', 1, 8),\n",
    "        'min_child_samples': trial.suggest_int('min_child_samples', 5, 1000),\n",
    "        'max_depth':trial.suggest_int('max_depth', 2, 64),\n",
    "        'seed':42,\n",
    "        'min_data_in_leaf':trial.suggest_int('min_data_in_leaf', 5, 1000)\n",
    "    }\n",
    "    \n",
    "    evals_result = {}\n",
    "    \"\"\"\n",
    "    model = lgb.train(param,\n",
    "                      lgb_train,\n",
    "                      valid_sets=[lgb_train, lgb_eval],# 訓練データを訓練用にセット\n",
    "                      verbose_eval=-1\n",
    "                     )\n",
    "    \"\"\"\n",
    "    # LightGBMで学習+予測\n",
    "    model = lgb.LGBMRegressor(**param,random_state=0)# 追加部分\n",
    "    \n",
    "    # kFold交差検定で決定係数を算出し、各セットの平均値を返す\n",
    "    kf = KFold(n_splits = 3, shuffle = True, random_state = 0)\n",
    "    scores = cross_validate(model, X = X_train, y = y_train,scoring = 'r2',cv = kf)   \n",
    "\n",
    "    return scores['test_score'].mean()\n",
    "\n",
    "    \"\"\"\n",
    "    kf = KFold(n_splits=4, shuffle=True, random_state=0)\n",
    "    scores = cross_validate(model.fit, X=train_x, y=train_y,scoring='r2',cv=kf)   \n",
    "    return scores['test_score'].mean()\n",
    "    \"\"\"\n",
    "    \"\"\"  \n",
    "    y_pred = model.predict(test_x)\n",
    "    rmse = mean_squared_error(test_y, y_pred, squared=False)\n",
    "    return rmse\n",
    "    \"\"\"\n",
    "    \n",
    "#optuna実行\n",
    "study = optuna.create_study(direction='maximize')\n",
    "study.optimize(objective, n_trials=100)\n",
    "print('params:', study.best_params)\n",
    "print('score:', study.best_value)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e1de11b-66f8-44e5-a586-e42c2443d023",
   "metadata": {},
   "outputs": [],
   "source": [
    "# xgboost\n",
    "def objective(trial):\n",
    "    # データを訓練用と検証用に分割する\n",
    "    train_x, test_x, train_y, test_y = train_test_split(X_train, y_train, test_size = 0.2, random_state = 6174)\n",
    "\n",
    "    # 1. パラメータと値の設定\n",
    "    # 最適化したいパラメータと，パラメータがとる値の範囲を指定する\n",
    "    params = {\n",
    "        \"n_estimators\": trial.suggest_int(\"n_estimators\", 100, 500),\n",
    "        \"max_depth\": trial.suggest_int(\"max_depth\", 3, 32),\n",
    "        \"max_leaves\": trial.suggest_int(\"max_leaves\", 1, 2048),\n",
    "        \"learning_rate\": trial.suggest_loguniform(\"learning_rate\", 1e-2, 1),\n",
    "        \"eta\" :  trial.suggest_loguniform('eta', 1e-7, 1.0),\n",
    "        \"gamma\" : trial.suggest_loguniform('gamma', 1e-7, 1.0),\n",
    "        \"min_child_weight\" : trial.suggest_loguniform('min_child_weight', 1e-7, 1.0),\n",
    "        \"max_delta_step\" : trial.suggest_loguniform('max_delta_step', 1e-7, 1.0),\n",
    "        \"subsample\" : trial.suggest_uniform('subsample', 0.0, 1.0),\n",
    "        \"reg_lambda\" : trial.suggest_uniform('reg_lambda', 0.0, 1000.0),\n",
    "        \"reg_alpha\" : trial.suggest_uniform('reg_alpha', 0.0, 1000.0)\n",
    "    }\n",
    "\n",
    "    # 2. モデルの訓練と評価\n",
    "    # モデルの訓練\n",
    "    model = xgb.XGBRegressor(**params)\n",
    "    model.fit(train_x, train_y)\n",
    "\n",
    "    # モデルの評価\n",
    "    pred = model.predict(test_x)\n",
    "    score = mean_squared_error(test_y, pred)\n",
    "\n",
    "    # 3. 目的関数の値を返す\n",
    "    # 今回は回帰問題のためRMSEの値を最小化することを目的とする\n",
    "    return score\n",
    "study = optuna.create_study(direction = 'minimize')\n",
    "study.optimize(objective, n_trials = 100)\n",
    "print('params:', study.best_params)\n",
    "print('score:', study.best_value)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
